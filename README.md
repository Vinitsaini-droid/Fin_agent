ğŸ§  Fin-Agent: A Modular, Self-Verifying AI Reasoning System



This repository contains a production-grade, agentic AI system designed for financial reasoning, retrieval-augmented intelligence, and explainable decision-making.



It is not a chatbot toy.



It is a controlled cognitive pipeline built around:



explicit reasoning stages,



verifiable outputs,



memory and personalization,



and strict cost / hallucination control.



The system runs entirely locally (or on your infra) and requires no external orchestration frameworks.



ğŸ§© What This System Actually Is



Fin-Agent is a single-agent architecture with internal cognition layers, inspired by how humans reason:



User â†’ Planner â†’ Thinker â†’ Verifier â†’ Explainer â†’ User





Each stage has a clear responsibility and is independently testable.



The agent:



retrieves information only when necessary



verifies its own answers before returning them



maintains long-term user context



avoids hallucinations by construction, not by prompt hacks



ğŸ—‚ï¸ Repository Structure

Fin\_agent/

â”‚

â”œâ”€â”€ chatbot\_ui.py              # Streamlit interface (entry point)

â”‚

â”œâ”€â”€ agent/

â”‚   â”œâ”€â”€ meta\_agent.py          # Routing + orchestration brain

â”‚   â”œâ”€â”€ planner.py             # Task decomposition

â”‚   â”œâ”€â”€ thinker.py             # Retrieval + reasoning

â”‚   â”œâ”€â”€ verifier.py            # Factual \& compliance validation

â”‚   â”œâ”€â”€ explainer.py           # Final answer synthesis

â”‚   â””â”€â”€ schemas.py             # Typed schemas for all components

â”‚

â”œâ”€â”€ memory/

â”‚   â”œâ”€â”€ memory\_manager.py      # Persistent user memory

â”‚   â”œâ”€â”€ chat\_summarizer.py     # Conversation compression

â”‚   â””â”€â”€ user\_profile\_store.py  # Preferences \& behavioral traits

â”‚

â”œâ”€â”€ retrieval/

â”‚   â”œâ”€â”€ pinecone\_client.py     # Vector DB access

â”‚   â”œâ”€â”€ semantic\_cache.py      # Query-level caching

â”‚   â”œâ”€â”€ query\_refiner.py       # Query rewriting / HyDE

â”‚   â””â”€â”€ context\_compressor.py  # Token-efficient summarization

â”‚

â”œâ”€â”€ prompts/

â”‚   â”œâ”€â”€ system\_base.txt

â”‚   â”œâ”€â”€ planner\_prompt.txt

â”‚   â”œâ”€â”€ thinker\_prompt.txt

â”‚   â”œâ”€â”€ verifier\_prompt.txt

â”‚   â””â”€â”€ explainer\_prompt.txt

â”‚

â”œâ”€â”€ evaluation/

â”‚   â”œâ”€â”€ ragas\_runner.py        # Automated evals

â”‚   â”œâ”€â”€ aspect\_critics.py      # Domain \& logic critics

â”‚   â””â”€â”€ trace\_logger.py

â”‚

â”œâ”€â”€ config/

â”‚   â”œâ”€â”€ settings.py

â”‚   â”œâ”€â”€ compliance\_rules.py

â”‚   â””â”€â”€ token\_budgets.py

â”‚

â”œâ”€â”€ utils/

â”‚   â”œâ”€â”€ llm\_client.py

â”‚   â”œâ”€â”€ json\_utils.py

â”‚   â”œâ”€â”€ similarity.py

â”‚   â””â”€â”€ logging.py

â”‚

â”œâ”€â”€ main\_agent.py              # Core execution pipeline

â”œâ”€â”€ chatbot\_ui.py              # Streamlit UI (run this)

â”œâ”€â”€ requirements.txt

â”œâ”€â”€ .env

â””â”€â”€ .gitignore



ğŸš€ Quick Start

1\. Create and activate environment

python -m venv venv

source venv/bin/activate   # Windows: venv\\Scripts\\activate



2\. Install dependencies

pip install -r requirements.txt



3\. Configure environment



Create a .env file:



OPENAI\_API\_KEY=your\_key\_here

PINECONE\_API\_KEY=your\_key

PINECONE\_ENV=your\_env





(Additional config options live in config/settings.py.)



â–¶ï¸ Running the System

Start the chatbot UI

streamlit run chatbot\_ui.py



What happens next:



User is asked for a user ID



System checks if the user already exists



If new â†’ profile initialization



Conversation begins



Memory, verification, and retrieval all run automatically



You interact with the agent like a normal chat â€” but internally itâ€™s executing a full reasoning pipeline.



ğŸ§  How the Agent Thinks (High Level)

1\. Meta Agent



Decides how to answer:



Simple â†’ fast path



Complex â†’ full reasoning chain



High risk â†’ verification enforced



2\. Planner



Breaks the query into structured steps and intents.



3\. Thinker



Retrieves knowledge only when needed, compresses it, and forms a draft answer.



4\. Verifier



Checks:



factual correctness



numerical validity



compliance constraints



If anything fails â†’ loop back.



5\. Explainer



Produces the final answer with:



concise reasoning



inline citations



zero chain-of-thought leakage



ğŸ§  Memory System



The agent remembers:



user preferences



risk tolerance



explanation depth



prior misunderstandings



Memory is:



summarized



token-bounded



scoped per user



This allows long-term personalization without bloating context windows.



ğŸ” Evaluation \& Safety



Built-in evaluation includes:



Faithfulness checks



Retrieval accuracy



Domain compliance



Numerical consistency



These run offline or periodically and do not affect latency.



ğŸ§ª Why This Architecture Works



No monolithic prompts



No hallucination-by-default



No uncontrolled tool calls



No wasted tokens



No blind trust in LLM output



You get predictable behavior, auditable reasoning, and scalable intelligence.



ğŸ§­ Final Note



This isnâ€™t a chatbot.

Itâ€™s a reasoning system with guardrails.



If you extend it carefully, you can build:



finance copilots



research agents



compliance assistants



internal decision engines



All without losing control of logic or cost.

